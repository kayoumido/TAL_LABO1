{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAL Labo 1d : application au français\n",
    "\n",
    "**Objectifs**\n",
    "\n",
    "Cette dernière partie (1d) du Labo1 reprend les instructions précédentes et les applique à des textes en français.  Il s'agit d'une part de gérer correctement l'encodage de l'alphabet avec les caractères spécifiques au français, et d'autre part de voir comment les outils NLTK gèrent une langue différente de l'anglais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Données proposées**\n",
    "\n",
    "* http://www.gutenberg.org/files/19040/19040-8.txt : livre en hongrois, ISO-8859-2 (latin2)\n",
    "* http://www.gutenberg.org/files/41211/41211-8.txt : livre en français, ISO-8859-1 (latin1)\n",
    "* http://www.gutenberg.org/files/28049/28049-0.txt : livre en polonais, UTF-8 (en Python noté 'utf-8' avec tiret) \n",
    "\n",
    "Tout d'abord, enregistrez ces fichiers depuis les URLs indiquées sur votre ordinateur (une seule consultation de chaque URL), avec l'encodage correct indiqué ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please write your Python code below and execute it.\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please write your Python code below and execute it.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant `open(filename, encoding='XXX', errors='replace')`, lisez dans une variable de type chaîne le contenu de chaque fichier, en essayant pour chacun des trois encodages (ou jeux de caractères) indiqués ci-dessus (latin1, latin2, ou utf-8).  Affichez un fragment de texte (100 à 200 caractères) et observez les différences, et si la lecture semble correcte ou non (vous aurez à remplir un tableau systématique plus bas).  Que se passe-t-il si vous n'indiquez aucun encodage lors de la lecture ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please write your Python code below and execute it.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veuillez résumer vos conclusions dans le tableau suivant.  Pour chaque fichier, indiquez si la lecture faite avec les différents encodages est correcte ou non, et si non, indiquez au moins un caractère qui est erronné.\n",
    "          \n",
    "| Fichier (format) / Lecture :  | utf8  | latin1  | latin2  | none |\n",
    "| ----------------------------- | ----- | ------- | ------- | ---- |\n",
    "| book_fr (original : latin1)   | ..    | ..      | ..      | ..   |\n",
    "| book_hu (original : latin2)   | ..    | ..      | ..      | ..   |\n",
    "| book_pl (original : utf-8)    | ..    | ..      | ..      | ..   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que se passe-t-il si vous n'utilisez pas l'option `errors='replace'` ?  Vous pouvez réutiliser le tableau pour indiquer les réponses à la question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please write your Python code below and execute it.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Écrivez maintenant chaque texte dans un fichier au format utf-8**, en supprimant comme précédemment les parties initiales et finales qui proviennent du site *Project Gutenberg* et qui ne font pas partie du texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Please write your Python code below and execute it.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parmi les trois segmentations ci-dessus, deux génèrent le même nombre de phrases noté *N*.  Testez si pour chaque *i* compris entre 1 et *N*, les *i*èmes phrases de chaque segmentation ont la même longueur en caractères et en mots, et affichez les valeurs de *i* pour lesquelles ces valeurs sont différentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please write your Python code below and execute it.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenization** (segmentation de chaque phrase en mots).  Comparer le tokenizer par défaut de NLTK (avec l'option `language='french'`) avec le tokenizer basé sur des expressions régulières fourni ci-après.  \n",
    "* Leurs résultats sont-ils identiques ?\n",
    "* Comparer les tokenizations de plusieurs phrases et indiquer quelle méthode est plus adaptée.\n",
    "* Comparez le nombre total de tokens obtenus par chaque méthode.\n",
    "* En regardant la documentation de `nltk.word_tokenize`, que pensez-vous de son adaptation au français ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please write your Python code below and execute it.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le tokenizer suivant utilise des expressions régulières.  Il est adapté de http://fabienpoulard.info/post/2008/03/05/Tokenisation-en-mots-avec-NLTK. Il peut être invoqué avec la méthode `tokenize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer_fr = nltk.RegexpTokenizer(r'''(?x)\n",
    "          \\d+(?:\\.\\d+)?\\s*%   # les pourcentages\n",
    "        | \\w'               # les contractions d', l', ...\n",
    "        | \\w+               # les mots pleins\n",
    "        | [^\\w\\s]           # les ponctuations\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please write your Python code below and execute it.\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please write your Python code below and execute it.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme dans les parties 1b et 1c, **veuillez écrire dans un fichier texte** appelé `book_fr.utf-8.tok.txt`le texte français tokenisé, avec des espaces entre les tokens et une phrase par ligne.  Utilisez la meilleure tokenization des deux précédentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'book_fr.utf-8.tok.txt'\n",
    "if os.path.exists(filename): \n",
    "    os.remove(filename)\n",
    "fd = open(filename, 'a', encoding='utf8')\n",
    "# Please write your Python code below and execute it.\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin de la partie 1d et du Labo1\n",
    "Veuillez nettoyer autant que possible ce _notebook_, exécutez une dernière fois toutes les cellules pour obtenir les résultats demandés, et enregistrez le _notebook_.  Puis ajoutez-le dans une archive _zip_ avec les _notebook_ des parties 1b et 1c, et soumettez l'archive individuellement sur Cyberlearn (_Laboratoire 1_). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
